O:9:"magpierss":20:{s:6:"parser";i:0;s:12:"current_item";a:0:{}s:5:"items";a:10:{i:0;a:12:{s:5:"title";s:37:"The OpenStreetmap New Data Model Army";s:4:"link";s:73:"http://mappinghacks.com/2007/04/19/the-openstreetmap-new-data-model-army/";s:8:"comments";s:82:"http://mappinghacks.com/2007/04/19/the-openstreetmap-new-data-model-army/#comments";s:7:"pubdate";s:31:"Thu, 19 Apr 2007 18:07:13 +0000";s:2:"dc";a:1:{s:7:"creator";s:2:"Jo";}s:8:"category";s:34:"collaborative mappingopenstreetmap";s:4:"guid";s:73:"http://mappinghacks.com/2007/04/19/the-openstreetmap-new-data-model-army/";s:11:"description";s:326:"Despite the fact I understood no more than one word in 12, I enjoyed FOSSGIS.de 2007, a long month ago now, a great deal. The &#8220;Freie Geodaten&#8221; movement here in Germany is the most active and developed I have seen. I spent an enjoyable afternoon talking with Jochen Topf about everything under the Sun related [...]";s:7:"content";a:1:{s:7:"encoded";s:12062:"<p>Despite the fact I understood no more than one word in 12, I enjoyed <a href="http://fossgis.de">FOSSGIS.de 2007</a>, a long month ago now, a great deal. The &#8220;Freie Geodaten&#8221; movement here in Germany is the most active and developed I have seen. I spent an enjoyable afternoon talking with <a href="http://www.remote.org/">Jochen Topf</a> about everything under the Sun related to the <a href="http://www.openstreetmap.org">OpenStreetmap</a> project.</p>
<p>I was delighted last week to read the white paper <a href="http://www.remote.org/frederik/tmp/towards-a-new-data-model-for-osm.pdf">Towards a New Data Model for OpenStreetmap</a> (PDF) that Jochen produced with Frederik Ramm; I&#8217;d urge everyone who has contributed to the project in the past, or cares about its future, to print it out, read it on the bus, and send back notes or patches.</p>
<p>The current OSM data model is &#8220;topological&#8221;, and quite unlike standard GIS data backends which make use of geometry primitives. &#8220;Nodes&#8221; represent points, segments joining two nodes are simple lines, and &#8220;ways&#8221; are multi-segment, complex lines, sometimes used as shapes. These are the basic units of the current model; they are then annotated with open attributes, pairs of keys and values, both of which are free-text, like tags. (&#8221;highway=primary&#8221; or &#8220;name=Oxford Street&#8221;&#8230; My all-time favourite OSM tag is still &#8220;horse=yes&#8221;).</p>
<p>This New Data Model moves away from the focus primarily on spatial things, instead outlining &#8220;abstract objects&#8221; which can have spatial attributes - can be connected to one or more geometries, and have additional sets of properties. The scheme - an abstract object with a UUID or URL identifier, annotated with properties which come from defined namespaces and are to some degree &#8220;controlled&#8221; by the implementor, looks much more RDF-like to my eyes, and thus appeals to me.</p>
<p>Why more abstraction in a data model? Why not just follow best practise in Geographic Information Systems, buy a copy of ISO19109 and implement an echo of it? In many fields we rely too much on what we have inherited from mind-generations of specialists. The original OSM model was a kind of &#8220;<em>naive GIS</em>&#8220;, a rough consensus on &#8220;the simplest thing that could possibly work&#8221;. As the project and the data in it matures, it fails to communicate clearly even simple edge cases. (The central example is a footpath and a major road both running over a bridge; both have a section which runs over a bridge, there&#8217;s no way of stating that both &#8220;share&#8221; &#8220;the same&#8221; bridge.)</p>
<p>For more detail, I urge you again to read the paper. The notes that follow comment and expand upon it, and may make varying amounts of sense to one who has not read it.</p>
<ol>
<li><strong>Audit</strong> (which I think of as an umbrella term for change tracking, logging, versioning and reversion). I liked a lot the reasons given in the introductory &#8220;why to audit&#8221; section, glimpses of wiki nature for structured data:
<ul>
<li>Attaching granular changes to people</li>
<li>Being able to track changes to objects one has changed oneself</li>
<li>Being able to comment on changesets (like subversion commit comments) but also being able to comment on changesets distributed over time but connected by a theme or process (&#8221;trying to get the model right for X&#8221;)</li>
<li>Being able to do rollback on arbitrary changesets</li>
</ul>
<p>BUT, what&#8217;s missing in the New Model is any reflection of this in the API. The sketch of a new RESTful API is, well, sketchy, perhaps teasing the reader to complete it. Wanting to know more, do I have to suggest more? All i can provide is references. Rufus has been working on an interesting and functional prototype for versioned data models for the <a href="http://blog.okfn.org/">Open Knowledge Foundation</a>&#8217;s Comprehensive Knowledge Archive project. Contributors to the <a href="http://geoserver.org/">Geoserver</a> project have been experimenting with a <a href="http://docs.codehaus.org/display/GEOS/Versioning+WFS">versioning extension to the Web Feature Service - Transactional</a> protocol for publishing vector geodata. There&#8217;s good ground for rough consensus here, and both projects have running code.</li>
<li><strong>Read/write client support for a New Data Model</strong>. Another intriguing blank space; without a candidate API to test against, how can one tell how hard a backend migration might be? As one of those people who runs screaming from human-user-interface problems, I&#8217;d like to hear the perspective of a client implementor on how hard it would be to move from a geometry-centric, open-&#8221;tag&#8221; model to a more structured, abstract-object-centric, geometry-as-property model.</li>
<li><strong>Filtering the OSM data for different use cases (dynamic queries, or level of detail in map display).</strong>The goal state is to produce a subset of OSM data for a given extent - filtered, maybe generalised, according to the type of shape. The New Data Model document has a solid treatment of why this is needed, and why the open-key-value approach is making it progressively harder to do. Another topic that&#8217;s a core concern, yet the way in which the putative New Data Model deals with it is not spelled out.One way to filter is on the semantics of attributes of shapes - the simplest case, display a road or not according to how &#8216;major&#8217; it is. One interesting consideration is what happens when one gets down to a very fine level of detail, as some wish to do; an example given is the location of a tube station. Zoomed out, it&#8217;s just a dot; zoomed right in, one wants a point to represent each individual exit at an intersection.
<p>But then what happens to the nearby geometries? The roads that meet at Oxford Circus are lines, whose width is a side-effect of how they are being displayed. At a &#8220;MasterMap&#8221;, 1-1 correspondance level of detail, those lines would be polygons, areas with dimension. The New Model could attach several different kinds of geometries to one abstract feature, corresponding to different levels of detail in display.</p>
<p>This leads into several side-tracks. The little I know of ISO19109 (GIS Application Schema) is that it differentiates between &#8220;meta level, application level and data level&#8221; descriptions of things in space. Application level in this context is cartographic display - selection, arrangement of things on a map. A problem with the tagspace approach is it doesn&#8217;t differentiate between spatial semantics, and cartographic semantics (This section of street is physically 10 metres wide; this section of street is &#8220;primary&#8221;, therefore is displayed as 10px wide at this resolution). Perhaps a difference between &#8220;application level&#8221; and &#8220;data level&#8221; isn&#8217;t so easy or clear to define.</p>
<p>This has some odd implications for geospatial data licensing. Pace the EDINA paper which had some fun <a href="http://blog.okfn.org/2007/04/01/copyright-not-applicable-to-geodata/#comments">commentary at OKFN</a> and which the <a href="http://society.guardian.co.uk/e-public/story/0,,2050028,00.html">Guardian covered</a> recently; there&#8217;s a big difference between data which is there to be collected, and data which is the result of creative effort in compilation, in licensing terms.</p>
<p><em>If the &#8220;collection&#8221; element is removed as a criterion for originality and thus database copyright, focus must be on selection and arrangement of the materials in the database - the qualitative or expressive part of the test&#8221;</em></p>
<p>To state, &#8220;this section of street is 10 metres wide&#8221; is a fact collected from the world, which anyone can collect from the world&#8221;. To state, &#8220;this section of street is primary&#8221; - is that a qualitative or expressive description which others may or may not agree with? To design a data model in an attempt to protect oneself from property-oriented &#8220;data rights&#8221; law - is this a useful, or just a quixotic, consideration?</p>
<p>End of digression, back to the notes.</p>
<p><strong>The question of distributed revisions and distributed reversion</strong>. This is something I&#8217;m looking for, more than is spelled out in the New Data Model. It connects to &#8220;identity&#8221; of contributors, and federating identity between different read/write data access points. Imagine a parallel universe in which read/write - e.g. transactional - clients were writing back to different physical instances of a data store. Subsequently all the changes are being collected into one central &#8220;view&#8221; of the world depicted. Given this parallel universe also contains a satisfactory way to conflate changes - e.g. one original geometry is changed in 2 different ways by 2 different people and subsequently resolved back into one changed object. (I recall seeing a good presentation on doing this at OSGeo &#8216;05 in Minneapolis&#8230;)What subsequently happens when one wants to do distributed reversion? E.g., to subsequently decide that one set of changes to a shape was &#8220;unreliable&#8221; but the other wasn&#8217;t. Would one have to rollback the geometry to its original state, then subsequently re-apply one set of changes but not the other, creating a revised version?</p>
<p>Perhaps this is the view from Mars - I love to speculate about solutions to problems we don&#8217;t yet have, but can only predict. Yet this looks obvious to me - a problem that we can&#8217;t avoid having. The conviction that, for technological, social and legal reasons alike, OSM will one day have to federate its data store, goes back with me a long way. Frederik and Jochen don&#8217;t think so - the paper states that a central data cluster, one ring to rule them all, is the only thng viable now. Perhaps to suggest otherwise is to unwisely invite contention.</li>
<li><strong>The question of 2 types of nodes.</strong> In the current model, nodes (and the segment arcs that join them) denote physical features, bends or joins in lines - the topology of physical things. Nodes can also be useful to denote abstractions - things that are not physical properties of streets, but more like legal or behavioural properties of them (e.g. &#8220;the span of this street between node A and node B has a speed limit of 20mph&#8221;).How would this work in the New Data Model? Would a geometry be created that was attached to an abstract object (the street) indicating the stretch with a different speed limit? Would we then rely on geometrical queries to &#8220;identify&#8221; that span with a distinct geometry that describes the street?</li>
<li><strong>The question of apparent dimensionality.</strong> One of my favourite phrases in the whole paper was this, in one of the highlighted &#8220;requests for comments&#8221; sections:<br />
<blockquote><p><span class="yellow"><em>Discuss whether it may be necessary to allow using edges of areas as linear features, or faces of 3D objects as areas?</em></span></p></blockquote>
<p>Are tuples expressive enough? Do the 3D modelling capacities currently available in GIS or CAD data stores address this question?</li>
</ol>
<p>Enough idle speculation. What this boils down to is, as ever: each set of newcomers to spatial information modelling see old questions in new ways; I&#8217;m not convinced that the state of the art in GIS databases has appropriate answers. The OSM community, as ever, creates new cart-tracks across well-paved spaces. The debate is too heated for any but the really committed to follow, the tracks become effaced in debate, but perhaps they&#8217;re leading somewhere new. Or as the New Data Model paper puts it,</p>
<blockquote><p><strong>Complexity does not mean that it has to be more complicated.</strong></p></blockquote>
";}s:3:"wfw";a:1:{s:10:"commentrss";s:78:"http://mappinghacks.com/2007/04/19/the-openstreetmap-new-data-model-army/feed/";}s:7:"summary";s:326:"Despite the fact I understood no more than one word in 12, I enjoyed FOSSGIS.de 2007, a long month ago now, a great deal. The &#8220;Freie Geodaten&#8221; movement here in Germany is the most active and developed I have seen. I spent an enjoyable afternoon talking with Jochen Topf about everything under the Sun related [...]";s:12:"atom_content";s:12062:"<p>Despite the fact I understood no more than one word in 12, I enjoyed <a href="http://fossgis.de">FOSSGIS.de 2007</a>, a long month ago now, a great deal. The &#8220;Freie Geodaten&#8221; movement here in Germany is the most active and developed I have seen. I spent an enjoyable afternoon talking with <a href="http://www.remote.org/">Jochen Topf</a> about everything under the Sun related to the <a href="http://www.openstreetmap.org">OpenStreetmap</a> project.</p>
<p>I was delighted last week to read the white paper <a href="http://www.remote.org/frederik/tmp/towards-a-new-data-model-for-osm.pdf">Towards a New Data Model for OpenStreetmap</a> (PDF) that Jochen produced with Frederik Ramm; I&#8217;d urge everyone who has contributed to the project in the past, or cares about its future, to print it out, read it on the bus, and send back notes or patches.</p>
<p>The current OSM data model is &#8220;topological&#8221;, and quite unlike standard GIS data backends which make use of geometry primitives. &#8220;Nodes&#8221; represent points, segments joining two nodes are simple lines, and &#8220;ways&#8221; are multi-segment, complex lines, sometimes used as shapes. These are the basic units of the current model; they are then annotated with open attributes, pairs of keys and values, both of which are free-text, like tags. (&#8221;highway=primary&#8221; or &#8220;name=Oxford Street&#8221;&#8230; My all-time favourite OSM tag is still &#8220;horse=yes&#8221;).</p>
<p>This New Data Model moves away from the focus primarily on spatial things, instead outlining &#8220;abstract objects&#8221; which can have spatial attributes - can be connected to one or more geometries, and have additional sets of properties. The scheme - an abstract object with a UUID or URL identifier, annotated with properties which come from defined namespaces and are to some degree &#8220;controlled&#8221; by the implementor, looks much more RDF-like to my eyes, and thus appeals to me.</p>
<p>Why more abstraction in a data model? Why not just follow best practise in Geographic Information Systems, buy a copy of ISO19109 and implement an echo of it? In many fields we rely too much on what we have inherited from mind-generations of specialists. The original OSM model was a kind of &#8220;<em>naive GIS</em>&#8220;, a rough consensus on &#8220;the simplest thing that could possibly work&#8221;. As the project and the data in it matures, it fails to communicate clearly even simple edge cases. (The central example is a footpath and a major road both running over a bridge; both have a section which runs over a bridge, there&#8217;s no way of stating that both &#8220;share&#8221; &#8220;the same&#8221; bridge.)</p>
<p>For more detail, I urge you again to read the paper. The notes that follow comment and expand upon it, and may make varying amounts of sense to one who has not read it.</p>
<ol>
<li><strong>Audit</strong> (which I think of as an umbrella term for change tracking, logging, versioning and reversion). I liked a lot the reasons given in the introductory &#8220;why to audit&#8221; section, glimpses of wiki nature for structured data:
<ul>
<li>Attaching granular changes to people</li>
<li>Being able to track changes to objects one has changed oneself</li>
<li>Being able to comment on changesets (like subversion commit comments) but also being able to comment on changesets distributed over time but connected by a theme or process (&#8221;trying to get the model right for X&#8221;)</li>
<li>Being able to do rollback on arbitrary changesets</li>
</ul>
<p>BUT, what&#8217;s missing in the New Model is any reflection of this in the API. The sketch of a new RESTful API is, well, sketchy, perhaps teasing the reader to complete it. Wanting to know more, do I have to suggest more? All i can provide is references. Rufus has been working on an interesting and functional prototype for versioned data models for the <a href="http://blog.okfn.org/">Open Knowledge Foundation</a>&#8217;s Comprehensive Knowledge Archive project. Contributors to the <a href="http://geoserver.org/">Geoserver</a> project have been experimenting with a <a href="http://docs.codehaus.org/display/GEOS/Versioning+WFS">versioning extension to the Web Feature Service - Transactional</a> protocol for publishing vector geodata. There&#8217;s good ground for rough consensus here, and both projects have running code.</li>
<li><strong>Read/write client support for a New Data Model</strong>. Another intriguing blank space; without a candidate API to test against, how can one tell how hard a backend migration might be? As one of those people who runs screaming from human-user-interface problems, I&#8217;d like to hear the perspective of a client implementor on how hard it would be to move from a geometry-centric, open-&#8221;tag&#8221; model to a more structured, abstract-object-centric, geometry-as-property model.</li>
<li><strong>Filtering the OSM data for different use cases (dynamic queries, or level of detail in map display).</strong>The goal state is to produce a subset of OSM data for a given extent - filtered, maybe generalised, according to the type of shape. The New Data Model document has a solid treatment of why this is needed, and why the open-key-value approach is making it progressively harder to do. Another topic that&#8217;s a core concern, yet the way in which the putative New Data Model deals with it is not spelled out.One way to filter is on the semantics of attributes of shapes - the simplest case, display a road or not according to how &#8216;major&#8217; it is. One interesting consideration is what happens when one gets down to a very fine level of detail, as some wish to do; an example given is the location of a tube station. Zoomed out, it&#8217;s just a dot; zoomed right in, one wants a point to represent each individual exit at an intersection.
<p>But then what happens to the nearby geometries? The roads that meet at Oxford Circus are lines, whose width is a side-effect of how they are being displayed. At a &#8220;MasterMap&#8221;, 1-1 correspondance level of detail, those lines would be polygons, areas with dimension. The New Model could attach several different kinds of geometries to one abstract feature, corresponding to different levels of detail in display.</p>
<p>This leads into several side-tracks. The little I know of ISO19109 (GIS Application Schema) is that it differentiates between &#8220;meta level, application level and data level&#8221; descriptions of things in space. Application level in this context is cartographic display - selection, arrangement of things on a map. A problem with the tagspace approach is it doesn&#8217;t differentiate between spatial semantics, and cartographic semantics (This section of street is physically 10 metres wide; this section of street is &#8220;primary&#8221;, therefore is displayed as 10px wide at this resolution). Perhaps a difference between &#8220;application level&#8221; and &#8220;data level&#8221; isn&#8217;t so easy or clear to define.</p>
<p>This has some odd implications for geospatial data licensing. Pace the EDINA paper which had some fun <a href="http://blog.okfn.org/2007/04/01/copyright-not-applicable-to-geodata/#comments">commentary at OKFN</a> and which the <a href="http://society.guardian.co.uk/e-public/story/0,,2050028,00.html">Guardian covered</a> recently; there&#8217;s a big difference between data which is there to be collected, and data which is the result of creative effort in compilation, in licensing terms.</p>
<p><em>If the &#8220;collection&#8221; element is removed as a criterion for originality and thus database copyright, focus must be on selection and arrangement of the materials in the database - the qualitative or expressive part of the test&#8221;</em></p>
<p>To state, &#8220;this section of street is 10 metres wide&#8221; is a fact collected from the world, which anyone can collect from the world&#8221;. To state, &#8220;this section of street is primary&#8221; - is that a qualitative or expressive description which others may or may not agree with? To design a data model in an attempt to protect oneself from property-oriented &#8220;data rights&#8221; law - is this a useful, or just a quixotic, consideration?</p>
<p>End of digression, back to the notes.</p>
<p><strong>The question of distributed revisions and distributed reversion</strong>. This is something I&#8217;m looking for, more than is spelled out in the New Data Model. It connects to &#8220;identity&#8221; of contributors, and federating identity between different read/write data access points. Imagine a parallel universe in which read/write - e.g. transactional - clients were writing back to different physical instances of a data store. Subsequently all the changes are being collected into one central &#8220;view&#8221; of the world depicted. Given this parallel universe also contains a satisfactory way to conflate changes - e.g. one original geometry is changed in 2 different ways by 2 different people and subsequently resolved back into one changed object. (I recall seeing a good presentation on doing this at OSGeo &#8216;05 in Minneapolis&#8230;)What subsequently happens when one wants to do distributed reversion? E.g., to subsequently decide that one set of changes to a shape was &#8220;unreliable&#8221; but the other wasn&#8217;t. Would one have to rollback the geometry to its original state, then subsequently re-apply one set of changes but not the other, creating a revised version?</p>
<p>Perhaps this is the view from Mars - I love to speculate about solutions to problems we don&#8217;t yet have, but can only predict. Yet this looks obvious to me - a problem that we can&#8217;t avoid having. The conviction that, for technological, social and legal reasons alike, OSM will one day have to federate its data store, goes back with me a long way. Frederik and Jochen don&#8217;t think so - the paper states that a central data cluster, one ring to rule them all, is the only thng viable now. Perhaps to suggest otherwise is to unwisely invite contention.</li>
<li><strong>The question of 2 types of nodes.</strong> In the current model, nodes (and the segment arcs that join them) denote physical features, bends or joins in lines - the topology of physical things. Nodes can also be useful to denote abstractions - things that are not physical properties of streets, but more like legal or behavioural properties of them (e.g. &#8220;the span of this street between node A and node B has a speed limit of 20mph&#8221;).How would this work in the New Data Model? Would a geometry be created that was attached to an abstract object (the street) indicating the stretch with a different speed limit? Would we then rely on geometrical queries to &#8220;identify&#8221; that span with a distinct geometry that describes the street?</li>
<li><strong>The question of apparent dimensionality.</strong> One of my favourite phrases in the whole paper was this, in one of the highlighted &#8220;requests for comments&#8221; sections:<br />
<blockquote><p><span class="yellow"><em>Discuss whether it may be necessary to allow using edges of areas as linear features, or faces of 3D objects as areas?</em></span></p></blockquote>
<p>Are tuples expressive enough? Do the 3D modelling capacities currently available in GIS or CAD data stores address this question?</li>
</ol>
<p>Enough idle speculation. What this boils down to is, as ever: each set of newcomers to spatial information modelling see old questions in new ways; I&#8217;m not convinced that the state of the art in GIS databases has appropriate answers. The OSM community, as ever, creates new cart-tracks across well-paved spaces. The debate is too heated for any but the really committed to follow, the tracks become effaced in debate, but perhaps they&#8217;re leading somewhere new. Or as the New Data Model paper puts it,</p>
<blockquote><p><strong>Complexity does not mean that it has to be more complicated.</strong></p></blockquote>
";}i:1;a:12:{s:5:"title";s:35:"Open Geodata and Open Knowledge 1.0";s:4:"link";s:52:"http://mappinghacks.com/2007/02/12/open-knowledge-1/";s:8:"comments";s:61:"http://mappinghacks.com/2007/02/12/open-knowledge-1/#comments";s:7:"pubdate";s:31:"Mon, 12 Feb 2007 09:48:52 +0000";s:2:"dc";a:1:{s:7:"creator";s:2:"Jo";}s:8:"category";s:47:"eventslondonopen knowledgemetadataopenstreetmap";s:4:"guid";s:70:"http://mappinghacks.com/2007/02/12/open-geodata-and-open-knowledge-10/";s:11:"description";s:366:"I&#8217;m looking forward to being in London on March 17th for Open Knowledge 1.0. This is one day event is on the theme of &#8220;Atomisation and Commercial Opportunity&#8221; for free, collectively produced data in different domains, including panels on open media, open geodata and open scientific and civic information.
The open geodata panel this year has [...]";s:7:"content";a:1:{s:7:"encoded";s:1835:"<p>I&#8217;m looking forward to being in London on March 17th for <a href="http://okfn.org/okcon/">Open Knowledge 1.0</a>. This is one day event is on the theme of &#8220;Atomisation and Commercial Opportunity&#8221; for free, collectively produced data in different domains, including panels on open media, open geodata and open scientific and civic information.</p>
<p>The open geodata panel this year has a great lineup who should have a lot to say to one another:</p>
<ul>
<li><a href="http://www.edparsons.com">Ed Parsons</a>, who resigned as CTO of the Ordnance Survey late last year, and whose increasing blog-warmth about open geodata has been great to watch,</li>
<li><a href="http://www.freeourdata.org.uk/blog/index.php">Charles Arthur</a>, one of the founders and principal actor behind the Guardian´s Free Our Data initiative</li>
<li><a href="http://www.asklater.com/steve/">Steve Coast</a>, founder of the OpenStreetmap.org project</li>
</ul>
<p>The rest of the OK1 lineup is pretty stellar, too, including <a href="http://wwmm.ch.cam.ac.uk/blogs/murrayrust/">Peter Murray-Rust</a> on open chemical data - more people will remember him from the foundational XML-dev and early semantic web work - John Sheridan from the Office of Public Sector Information,  who&#8217;s involved in doing spatial RDF projects there, and Zoe Young of the <a href="http://www.transmission.cc/">transmission.cc</a> film distribution network, whose <a href="http://wiki.transmission.cc/index.php/Metadata_working_group">metadata working group</a> i´ve been kibitzing on.</p>
<p>While these things are more about the crowd than the sessions, I hope we´ve found a good balance. If you&#8217;re near London and this tweaks your interest, then please <a href="http://www.okfn.org/okcon/register">register now to avoid disappointment</a>.
</p>
";}s:3:"wfw";a:1:{s:10:"commentrss";s:57:"http://mappinghacks.com/2007/02/12/open-knowledge-1/feed/";}s:7:"summary";s:366:"I&#8217;m looking forward to being in London on March 17th for Open Knowledge 1.0. This is one day event is on the theme of &#8220;Atomisation and Commercial Opportunity&#8221; for free, collectively produced data in different domains, including panels on open media, open geodata and open scientific and civic information.
The open geodata panel this year has [...]";s:12:"atom_content";s:1835:"<p>I&#8217;m looking forward to being in London on March 17th for <a href="http://okfn.org/okcon/">Open Knowledge 1.0</a>. This is one day event is on the theme of &#8220;Atomisation and Commercial Opportunity&#8221; for free, collectively produced data in different domains, including panels on open media, open geodata and open scientific and civic information.</p>
<p>The open geodata panel this year has a great lineup who should have a lot to say to one another:</p>
<ul>
<li><a href="http://www.edparsons.com">Ed Parsons</a>, who resigned as CTO of the Ordnance Survey late last year, and whose increasing blog-warmth about open geodata has been great to watch,</li>
<li><a href="http://www.freeourdata.org.uk/blog/index.php">Charles Arthur</a>, one of the founders and principal actor behind the Guardian´s Free Our Data initiative</li>
<li><a href="http://www.asklater.com/steve/">Steve Coast</a>, founder of the OpenStreetmap.org project</li>
</ul>
<p>The rest of the OK1 lineup is pretty stellar, too, including <a href="http://wwmm.ch.cam.ac.uk/blogs/murrayrust/">Peter Murray-Rust</a> on open chemical data - more people will remember him from the foundational XML-dev and early semantic web work - John Sheridan from the Office of Public Sector Information,  who&#8217;s involved in doing spatial RDF projects there, and Zoe Young of the <a href="http://www.transmission.cc/">transmission.cc</a> film distribution network, whose <a href="http://wiki.transmission.cc/index.php/Metadata_working_group">metadata working group</a> i´ve been kibitzing on.</p>
<p>While these things are more about the crowd than the sessions, I hope we´ve found a good balance. If you&#8217;re near London and this tweaks your interest, then please <a href="http://www.okfn.org/okcon/register">register now to avoid disappointment</a>.
</p>
";}i:2;a:12:{s:5:"title";s:33:"conceptual route maps, circa 1675";s:4:"link";s:68:"http://mappinghacks.com/2006/12/26/conceptual-route-maps-circa-1675/";s:8:"comments";s:77:"http://mappinghacks.com/2006/12/26/conceptual-route-maps-circa-1675/#comments";s:7:"pubdate";s:31:"Tue, 26 Dec 2006 22:30:14 +0000";s:2:"dc";a:1:{s:7:"creator";s:2:"Jo";}s:8:"category";s:20:"cartographichistoric";s:4:"guid";s:68:"http://mappinghacks.com/2006/12/26/conceptual-route-maps-circa-1675/";s:11:"description";s:300:"I am the only one of my friends regularly able to walk past a map shop without skipping a beat. And i&#8217;d almost managed to walk past &#8220;Mostly Maps&#8221; in Hay, before doubletaking at what was in the corner of my eye, rushing back and pressing my nose to the window like an urchin on [...]";s:7:"content";a:1:{s:7:"encoded";s:2004:"<p>I am the only one of my friends regularly able to walk past a map shop without skipping a beat. And i&#8217;d almost managed to walk past &#8220;<a href="http://www.mostlymaps.com/">Mostly Maps</a>&#8221; in Hay, before doubletaking at what was in the corner of my eye, rushing back and pressing my nose to the window like an urchin on Christmas Eve (which it was, and which i am).</p>
<p><a href="http://www.geog.port.ac.uk/webmap/hantsmap/hantsmap/ogilby/og97smar.htm"><img alt="john ogilby hampshire map, 1675" title="john ogilby hampshire map, 1675" src="http://frot.org/img/og97smal.jpg" /></a></p>
<p>I thought, <a href="http://graphics.stanford.edu/papers/routemaps/">kids at Stanford work on algorithms for this sort of thing and think they&#8217;re hot shit</a>; these are conceptual route maps,  focused on transport networks and orienting feature points. The seventeenth century equivalent of routefinding systems; space unscrolling, unscrolling between keystones on the King&#8217;s highway.</p>
<p><a href="http://en.wikipedia.org/wiki/John_Ogilby">Ogilby</a>&#8217;s maps formed representational conventions for centuries, standardised the mile, and had unknowable impact on the future of the English transport network. Plus, they are a things of beauty.</p>
<p>On the same trip through Hay i finally picked up a copy of <a href="http://en.wikipedia.org/wiki/The_Oregon_Experiment"><em>The Oregon Experiment</em></a> - the small &#8220;pragmatic participatory planning&#8221; volume of the trilogy otherwise comprised by <em><a href="http://en.wikipedia.org/wiki/A_Pattern_Language">A Pattern Language</a></em> and <em><a href="http://en.wikipedia.org/wiki/The_Timeless_Way_of_Building">The Timeless Way of Building</a></em>. It doesn&#8217;t have the tensile integrity of the other books, and comes off as quite smug. I wonder if it helped nudge the phrase &#8220;architecture of participation&#8221; into existence. I&#8217;d like to write a pile more about this some other time.
</p>
";}s:3:"wfw";a:1:{s:10:"commentrss";s:73:"http://mappinghacks.com/2006/12/26/conceptual-route-maps-circa-1675/feed/";}s:7:"summary";s:300:"I am the only one of my friends regularly able to walk past a map shop without skipping a beat. And i&#8217;d almost managed to walk past &#8220;Mostly Maps&#8221; in Hay, before doubletaking at what was in the corner of my eye, rushing back and pressing my nose to the window like an urchin on [...]";s:12:"atom_content";s:2004:"<p>I am the only one of my friends regularly able to walk past a map shop without skipping a beat. And i&#8217;d almost managed to walk past &#8220;<a href="http://www.mostlymaps.com/">Mostly Maps</a>&#8221; in Hay, before doubletaking at what was in the corner of my eye, rushing back and pressing my nose to the window like an urchin on Christmas Eve (which it was, and which i am).</p>
<p><a href="http://www.geog.port.ac.uk/webmap/hantsmap/hantsmap/ogilby/og97smar.htm"><img alt="john ogilby hampshire map, 1675" title="john ogilby hampshire map, 1675" src="http://frot.org/img/og97smal.jpg" /></a></p>
<p>I thought, <a href="http://graphics.stanford.edu/papers/routemaps/">kids at Stanford work on algorithms for this sort of thing and think they&#8217;re hot shit</a>; these are conceptual route maps,  focused on transport networks and orienting feature points. The seventeenth century equivalent of routefinding systems; space unscrolling, unscrolling between keystones on the King&#8217;s highway.</p>
<p><a href="http://en.wikipedia.org/wiki/John_Ogilby">Ogilby</a>&#8217;s maps formed representational conventions for centuries, standardised the mile, and had unknowable impact on the future of the English transport network. Plus, they are a things of beauty.</p>
<p>On the same trip through Hay i finally picked up a copy of <a href="http://en.wikipedia.org/wiki/The_Oregon_Experiment"><em>The Oregon Experiment</em></a> - the small &#8220;pragmatic participatory planning&#8221; volume of the trilogy otherwise comprised by <em><a href="http://en.wikipedia.org/wiki/A_Pattern_Language">A Pattern Language</a></em> and <em><a href="http://en.wikipedia.org/wiki/The_Timeless_Way_of_Building">The Timeless Way of Building</a></em>. It doesn&#8217;t have the tensile integrity of the other books, and comes off as quite smug. I wonder if it helped nudge the phrase &#8220;architecture of participation&#8221; into existence. I&#8217;d like to write a pile more about this some other time.
</p>
";}i:3;a:12:{s:5:"title";s:36:"At the back of the ?mass market? bus";s:4:"link";s:70:"http://mappinghacks.com/2006/12/14/at-the-back-of-the-mass-market-bus/";s:8:"comments";s:79:"http://mappinghacks.com/2006/12/14/at-the-back-of-the-mass-market-bus/#comments";s:7:"pubdate";s:31:"Thu, 14 Dec 2006 17:40:48 +0000";s:2:"dc";a:1:{s:7:"creator";s:2:"Jo";}s:8:"category";s:20:"geodataservicesosgeo";s:4:"guid";s:70:"http://mappinghacks.com/2006/12/14/at-the-back-of-the-mass-market-bus/";s:11:"description";s:361:"Ed Parsons offers an upbeat description of the Open Geospatial Consortium&#8217;s &#8220;mass market&#8221; / interoperability process. As a member of the geolumpenproletariat, I spent some time over the last month or so attempting to engage with the WFS Simple public development process marshalled by our friend Raj Singh. I backed away from it a couple [...]";s:7:"content";a:1:{s:7:"encoded";s:9253:"<p>Ed Parsons offers an <a href="http://www.edparsons.com/?p=392">upbeat description of the Open Geospatial Consortium&#8217;s &#8220;mass market&#8221;</a> / interoperability process. As a member of the geolumpenproletariat, I spent some time over the last month or so attempting to engage with the <a href="http://www.ogcnetwork.net/wfssimple/">WFS Simple</a> public development process marshalled by our friend <a href="http://www.rajsingh.org/">Raj Singh</a>. I backed away from it a couple of weeks ago, and wrote down at the time some of the reasons why&#8230;</p>
<p>When I heard Raj give a presentation about the emerging WFS Simple specification at the <a href="http://blog.okfn.org/2006/11/02/mashing-up-is-hard-to-do/">UK Geospatial Mashups event back in October</a>, I was sold immediately. This was the Web Feature Service cut right back to the essentials - bounding box / temporal slice query, simplified keyword query, that&#8217;s it. Targeted at the &#8220;neogeography&#8221; audience, as I perceived it; a good fit for <a href="http://georss.org/">GeoRSS</a>, carrying data around using any number of data syndication formats. I wrote a GeoRSS/RDF aggregator library in python last year and this would be an ideal interface for it. My head also rang with the prospect of using WFS Simple to base a simple metadata discovery service on, very much in the way that Tom Kralidis has done over WFS to produce <a href="http://devgeo.cciw.ca/owscat/docs/index.html">OWSCat</a>.</p>
<p>Rather than being a formal standards project in which paid membership in the consortium is necessary for participation, Simple&#8217;s specification process is being run as part of the &#8216;<a href="http://www.ogcnetwork.net">OGC Network</a>&#8216; and actively encouraging open contribution from free software developers. A lot of people from the <a href="http://www.osgeo.org/">OSGeo</a> community signed up to the Simple discussion list; there&#8217;s a lot of interest in simpler standards to make vector data more distributable.</p>
<p>A few days later I had the chance to sit down and re-write <a href="http://project.knowledgeforge.net/consumotronic/trac/browser/bbox">bbox</a>, the GeoRSS aggregator and add a <a href="http://project.knowledgeforge.net/consumotronic/trac/browser/bbox/bbox/wfssimple.py">WFS Simple</a> interface to it; i had a lot of questions as a result of implementing what the informal specs described, which got fed back into the docs, and which produced a good feeling.</p>
<p>WFS Simple is directed at the casual implementor not versed in the more traditional ISO or OGC standards, a very selfconscious attempt to &#8220;lower the bar&#8221;. In this i found it successful; apart from time spent refactoring the original application, it took less than a couple of hours to do everything required in the spec except DescribeFeatureType, which there is still a lot of discussion about omitting or adapting. One viable suggestion of Raj&#8217;s is to put the metadata describing the objects in the repository (the features) into the metadata describing what the web service does and who to call about it (the GetCapabilities request).</p>
<p>There are problems with simplicity. Everyone has a different view of the simplest, least useless thing. Mine is pretty expansive; I want to see a way of doing Transactions without having to implement full WFS-Transactional. I reluctantly agree that this is a non-simple request; in which case I want an approved way of extending the query interface and advertising common extensions to it.</p>
<p>Others are particularly interested in the use of WFS-Simple to offer a carrier format of Atom or RSS decorated with GeoRSS and Dublin Core properties. In theory there&#8217;s nothing to stop one sending arbitrary formats over WFS proper - <a href="http://geoserver.org/">GeoServer</a> offers KML and GeoRSS outputs and is planning a JSON output. WFS client support is working to some extent in <a href="http://openlayers.org/">OpenLayers</a>. But WFS is often too slow to use real-time; there&#8217;s more value in a data synchronisation protocol to make local copies for processing purposes, or in a tile cache for many different renderings of vectors as different resolution bitmaps, for web mapping purposes.</p>
<p>I finally unsubscribed from the WFS Simple list yesterday. Not because I&#8217;m no longer interested in the protocol and planning to build it into different apps; but out of disillusionment with the discussion process and how the goals are being expressed and met.</p>
<p>I recall an audience reaction to Raj&#8217;s presentation at the Ordnance Survey; a meterologist who maintained that the full expressiveness of GML and WFS was necessary for them; they could not be compelled to accept a simpler alternative with less utility. One meme we had way back when writing &#8220;Mapping Hacks&#8221; was of &#8220;locative&#8221; vs &#8220;GIS&#8221; - the long tail, and the high priesthood, and the tendency of the priesthood to look at anything simplified, fuzzily accurate or incomplete, as somehow intrinsically inadequate. There&#8217;s also been a long thread about &#8220;spatial data infrastructures&#8221; vs the &#8220;geospatial web&#8221;, and how to integrate the two concepts.</p>
<p>I am not a fan of WFS or GML, but recognise there is wide support and a variety of sophisticated use cases which there is nothing else will answer fully enough. But i&#8217;m exasperated by the dismissive attitude often displayed by people deeply involved in the OGC and ISO standards processes, to &#8220;grassroots&#8221; developments formed without the knowledge in that deep involvement. OGC was happy enough to subsume GeoRSS into their own offering once the community had done the work of specifying it, but the RSS and RDF geoannotation work from which it emerged, is bypassed. The rest of this post is most of the last email i wrote to the Simple discuss list, before backing away from the OGCistas&#8230;</p>
<p><a href="http://goatee.net/2003/rss-history.html">RSS&#8217;s heritage</a> is in the Semantic Web (cf the ill-fated RDF-expressed RSS1, which was forked by Dave Winer into RSS2 over widespread community objections, and Atom was a Sam Ruby-led attempt to close the divide.  GeoRSS is being used to syndicate updates to data sets in public administrations, big publishing organisations, and has extensive support in open source geospatial software projects. It fits a market niche which is even larger than &#8220;annotating web pages&#8221;. The use of the URI as a UUID for any kind of object is a utility.</p>
<p>Raj&#8217;s use case emphasis for Simple Web Feature Services is on non-spatial elements and attributes which are connected to spatial features, coming out of excel spreadsheets, conventional databases, etc.</p>
<p>To me, a web service is a convenient interface to a repository of data and of utilities with which to manipulate it. Web services, while an awful lot better than having to screenscrape and steal data or having no data at all, aren&#8217;t &#8220;more valid&#8221; than having structured data available at a repeatable URI, which has the advantage of being discoverable and indexable by bots. The non-discoverability of OGC web services has led to layers of superfluous registry models, service discovery services, etc, all dancing around the issue of making data available where it can easily be found, repackaged and reused.</p>
<p>The &#8220;geospatial web&#8221; has been far ahead on &#8220;open data&#8221; or common structured data in pretty much every domain, including the low-hanging fruit of music and media. Good precedents in open standards and in collaboration between SMEs inside consortia have been set. But if the geospatial standards community continues on this path of isolating itself, of looking upstream to the ISO rather than downstream to the distributed neogeo developer community, it will miss out on being connected to amazing things.</p>
<p>So i&#8217;m surprised to see an effort in outreach and interoperability seemingly retreating into itself. I turned up to the WFS Simple development discussion process really pleased to hear of developments on a very simple, very implementable query interface which would generously support a variety of output formats. I&#8217;m losing sight of the value a bit now - it&#8217;s difficult to see more advantage to this than to, say, adding a bbox query option to OAI-PMH and building services on it; and that&#8217;s the path i&#8217;m going to follow for a while.</p>
<p>Essentially i want a specification to operate in the way a software project can so well - a small core and confined core, an extensive plugin architecture (e.g. encouragement to extend the query interface for specific purposes like basic transactions or feature/tileset metadata publishing), with every suggestion driven by a test case. I know that what I want for Simple probably falls between two stools - not expressive and flexible enough for the hardcore - not familiar and straightforward enough for the much larger neogeo constituency. Right now the process risks failing both communities and emphasising the difference between them, and that&#8217;s an awful shame.
</p>
";}s:3:"wfw";a:1:{s:10:"commentrss";s:75:"http://mappinghacks.com/2006/12/14/at-the-back-of-the-mass-market-bus/feed/";}s:7:"summary";s:361:"Ed Parsons offers an upbeat description of the Open Geospatial Consortium&#8217;s &#8220;mass market&#8221; / interoperability process. As a member of the geolumpenproletariat, I spent some time over the last month or so attempting to engage with the WFS Simple public development process marshalled by our friend Raj Singh. I backed away from it a couple [...]";s:12:"atom_content";s:9253:"<p>Ed Parsons offers an <a href="http://www.edparsons.com/?p=392">upbeat description of the Open Geospatial Consortium&#8217;s &#8220;mass market&#8221;</a> / interoperability process. As a member of the geolumpenproletariat, I spent some time over the last month or so attempting to engage with the <a href="http://www.ogcnetwork.net/wfssimple/">WFS Simple</a> public development process marshalled by our friend <a href="http://www.rajsingh.org/">Raj Singh</a>. I backed away from it a couple of weeks ago, and wrote down at the time some of the reasons why&#8230;</p>
<p>When I heard Raj give a presentation about the emerging WFS Simple specification at the <a href="http://blog.okfn.org/2006/11/02/mashing-up-is-hard-to-do/">UK Geospatial Mashups event back in October</a>, I was sold immediately. This was the Web Feature Service cut right back to the essentials - bounding box / temporal slice query, simplified keyword query, that&#8217;s it. Targeted at the &#8220;neogeography&#8221; audience, as I perceived it; a good fit for <a href="http://georss.org/">GeoRSS</a>, carrying data around using any number of data syndication formats. I wrote a GeoRSS/RDF aggregator library in python last year and this would be an ideal interface for it. My head also rang with the prospect of using WFS Simple to base a simple metadata discovery service on, very much in the way that Tom Kralidis has done over WFS to produce <a href="http://devgeo.cciw.ca/owscat/docs/index.html">OWSCat</a>.</p>
<p>Rather than being a formal standards project in which paid membership in the consortium is necessary for participation, Simple&#8217;s specification process is being run as part of the &#8216;<a href="http://www.ogcnetwork.net">OGC Network</a>&#8216; and actively encouraging open contribution from free software developers. A lot of people from the <a href="http://www.osgeo.org/">OSGeo</a> community signed up to the Simple discussion list; there&#8217;s a lot of interest in simpler standards to make vector data more distributable.</p>
<p>A few days later I had the chance to sit down and re-write <a href="http://project.knowledgeforge.net/consumotronic/trac/browser/bbox">bbox</a>, the GeoRSS aggregator and add a <a href="http://project.knowledgeforge.net/consumotronic/trac/browser/bbox/bbox/wfssimple.py">WFS Simple</a> interface to it; i had a lot of questions as a result of implementing what the informal specs described, which got fed back into the docs, and which produced a good feeling.</p>
<p>WFS Simple is directed at the casual implementor not versed in the more traditional ISO or OGC standards, a very selfconscious attempt to &#8220;lower the bar&#8221;. In this i found it successful; apart from time spent refactoring the original application, it took less than a couple of hours to do everything required in the spec except DescribeFeatureType, which there is still a lot of discussion about omitting or adapting. One viable suggestion of Raj&#8217;s is to put the metadata describing the objects in the repository (the features) into the metadata describing what the web service does and who to call about it (the GetCapabilities request).</p>
<p>There are problems with simplicity. Everyone has a different view of the simplest, least useless thing. Mine is pretty expansive; I want to see a way of doing Transactions without having to implement full WFS-Transactional. I reluctantly agree that this is a non-simple request; in which case I want an approved way of extending the query interface and advertising common extensions to it.</p>
<p>Others are particularly interested in the use of WFS-Simple to offer a carrier format of Atom or RSS decorated with GeoRSS and Dublin Core properties. In theory there&#8217;s nothing to stop one sending arbitrary formats over WFS proper - <a href="http://geoserver.org/">GeoServer</a> offers KML and GeoRSS outputs and is planning a JSON output. WFS client support is working to some extent in <a href="http://openlayers.org/">OpenLayers</a>. But WFS is often too slow to use real-time; there&#8217;s more value in a data synchronisation protocol to make local copies for processing purposes, or in a tile cache for many different renderings of vectors as different resolution bitmaps, for web mapping purposes.</p>
<p>I finally unsubscribed from the WFS Simple list yesterday. Not because I&#8217;m no longer interested in the protocol and planning to build it into different apps; but out of disillusionment with the discussion process and how the goals are being expressed and met.</p>
<p>I recall an audience reaction to Raj&#8217;s presentation at the Ordnance Survey; a meterologist who maintained that the full expressiveness of GML and WFS was necessary for them; they could not be compelled to accept a simpler alternative with less utility. One meme we had way back when writing &#8220;Mapping Hacks&#8221; was of &#8220;locative&#8221; vs &#8220;GIS&#8221; - the long tail, and the high priesthood, and the tendency of the priesthood to look at anything simplified, fuzzily accurate or incomplete, as somehow intrinsically inadequate. There&#8217;s also been a long thread about &#8220;spatial data infrastructures&#8221; vs the &#8220;geospatial web&#8221;, and how to integrate the two concepts.</p>
<p>I am not a fan of WFS or GML, but recognise there is wide support and a variety of sophisticated use cases which there is nothing else will answer fully enough. But i&#8217;m exasperated by the dismissive attitude often displayed by people deeply involved in the OGC and ISO standards processes, to &#8220;grassroots&#8221; developments formed without the knowledge in that deep involvement. OGC was happy enough to subsume GeoRSS into their own offering once the community had done the work of specifying it, but the RSS and RDF geoannotation work from which it emerged, is bypassed. The rest of this post is most of the last email i wrote to the Simple discuss list, before backing away from the OGCistas&#8230;</p>
<p><a href="http://goatee.net/2003/rss-history.html">RSS&#8217;s heritage</a> is in the Semantic Web (cf the ill-fated RDF-expressed RSS1, which was forked by Dave Winer into RSS2 over widespread community objections, and Atom was a Sam Ruby-led attempt to close the divide.  GeoRSS is being used to syndicate updates to data sets in public administrations, big publishing organisations, and has extensive support in open source geospatial software projects. It fits a market niche which is even larger than &#8220;annotating web pages&#8221;. The use of the URI as a UUID for any kind of object is a utility.</p>
<p>Raj&#8217;s use case emphasis for Simple Web Feature Services is on non-spatial elements and attributes which are connected to spatial features, coming out of excel spreadsheets, conventional databases, etc.</p>
<p>To me, a web service is a convenient interface to a repository of data and of utilities with which to manipulate it. Web services, while an awful lot better than having to screenscrape and steal data or having no data at all, aren&#8217;t &#8220;more valid&#8221; than having structured data available at a repeatable URI, which has the advantage of being discoverable and indexable by bots. The non-discoverability of OGC web services has led to layers of superfluous registry models, service discovery services, etc, all dancing around the issue of making data available where it can easily be found, repackaged and reused.</p>
<p>The &#8220;geospatial web&#8221; has been far ahead on &#8220;open data&#8221; or common structured data in pretty much every domain, including the low-hanging fruit of music and media. Good precedents in open standards and in collaboration between SMEs inside consortia have been set. But if the geospatial standards community continues on this path of isolating itself, of looking upstream to the ISO rather than downstream to the distributed neogeo developer community, it will miss out on being connected to amazing things.</p>
<p>So i&#8217;m surprised to see an effort in outreach and interoperability seemingly retreating into itself. I turned up to the WFS Simple development discussion process really pleased to hear of developments on a very simple, very implementable query interface which would generously support a variety of output formats. I&#8217;m losing sight of the value a bit now - it&#8217;s difficult to see more advantage to this than to, say, adding a bbox query option to OAI-PMH and building services on it; and that&#8217;s the path i&#8217;m going to follow for a while.</p>
<p>Essentially i want a specification to operate in the way a software project can so well - a small core and confined core, an extensive plugin architecture (e.g. encouragement to extend the query interface for specific purposes like basic transactions or feature/tileset metadata publishing), with every suggestion driven by a test case. I know that what I want for Simple probably falls between two stools - not expressive and flexible enough for the hardcore - not familiar and straightforward enough for the much larger neogeo constituency. Right now the process risks failing both communities and emphasising the difference between them, and that&#8217;s an awful shame.
</p>
";}i:4;a:12:{s:5:"title";s:47:"trackgpx2shp.pl and the Mapping Hacks code page";s:4:"link";s:82:"http://mappinghacks.com/2006/12/12/trackgpx2shppl-and-the-mapping-hacks-code-page/";s:8:"comments";s:91:"http://mappinghacks.com/2006/12/12/trackgpx2shppl-and-the-mapping-hacks-code-page/#comments";s:7:"pubdate";s:31:"Tue, 12 Dec 2006 17:26:34 +0000";s:2:"dc";a:1:{s:7:"creator";s:4:"Rich";}s:8:"category";s:13:"Uncategorized";s:4:"guid";s:82:"http://mappinghacks.com/2006/12/12/trackgpx2shppl-and-the-mapping-hacks-code-page/";s:11:"description";s:305:"In Mapping Hacks, the book, Schuyler wrote a program to convert a track log in a text file into a Shapefile.  We mentioned, perhaps optimistically, that a version to convert a gpx (a GPS XML exchange format) track lot to a shapefile would be on the web site.
Optimism while writing is a good, and a [...]";s:7:"content";a:1:{s:7:"encoded";s:749:"<p>In Mapping Hacks, the book, Schuyler wrote a program to convert a track log in a text file into a Shapefile.  We mentioned, perhaps optimistically, that a version to convert a gpx (a GPS XML exchange format) track lot to a shapefile would be on the web site.</p>
<p>Optimism while writing is a good, and a scary, thing.  I&#8217;ve <a href="/code/track2shp.zip">updated track2shp.zip </a>to include trackgpx2shp.pl, the program to convert a gpx file to a shapefile.</p>
<p>There are a few other things in the <a href="/code">Mapping Hacks code page</a>, and Google Maps Hacks examples on our <a href="/projects/gmaps">Google Maps project page.</a>   And the <a href="/projects">Mapping Hacks project page</a> has other bits of goodness.
</p>
";}s:3:"wfw";a:1:{s:10:"commentrss";s:87:"http://mappinghacks.com/2006/12/12/trackgpx2shppl-and-the-mapping-hacks-code-page/feed/";}s:7:"summary";s:305:"In Mapping Hacks, the book, Schuyler wrote a program to convert a track log in a text file into a Shapefile.  We mentioned, perhaps optimistically, that a version to convert a gpx (a GPS XML exchange format) track lot to a shapefile would be on the web site.
Optimism while writing is a good, and a [...]";s:12:"atom_content";s:749:"<p>In Mapping Hacks, the book, Schuyler wrote a program to convert a track log in a text file into a Shapefile.  We mentioned, perhaps optimistically, that a version to convert a gpx (a GPS XML exchange format) track lot to a shapefile would be on the web site.</p>
<p>Optimism while writing is a good, and a scary, thing.  I&#8217;ve <a href="/code/track2shp.zip">updated track2shp.zip </a>to include trackgpx2shp.pl, the program to convert a gpx file to a shapefile.</p>
<p>There are a few other things in the <a href="/code">Mapping Hacks code page</a>, and Google Maps Hacks examples on our <a href="/projects/gmaps">Google Maps project page.</a>   And the <a href="/projects">Mapping Hacks project page</a> has other bits of goodness.
</p>
";}i:5;a:12:{s:5:"title";s:21:"An Internet of Values";s:4:"link";s:57:"http://mappinghacks.com/2006/12/07/an-internet-of-values/";s:8:"comments";s:66:"http://mappinghacks.com/2006/12/07/an-internet-of-values/#comments";s:7:"pubdate";s:31:"Thu, 07 Dec 2006 19:06:45 +0000";s:2:"dc";a:1:{s:7:"creator";s:4:"Rich";}s:8:"category";s:33:"qpsychosoftwareInternet of Values";s:4:"guid";s:57:"http://mappinghacks.com/2006/12/07/an-internet-of-values/";s:11:"description";s:318:"The revolution will not be televised, and the revolution will not come from the creeping crudge of &#8216;The Internet of Things.&#8217;   I&#8217;m as excited as Bruce Sterling to have technology help me to keep track of my crap.  You won&#8217;t need to look for your shoes, you&#8217;ll be able to Google Your [...]";s:7:"content";a:1:{s:7:"encoded";s:4537:"<p>The revolution will not be televised, and the revolution will not come from the creeping crudge of &#8216;The Internet of Things.&#8217;   I&#8217;m as excited as Bruce Sterling to have technology help me to keep track of my crap.  You won&#8217;t need to look for your shoes, you&#8217;ll be able to Google Your Shoes!</p>
<p>And the truth will set us free.  The truth of knowing where we are in relation to the constellation of objects which we have allowed to assume the role of defining who we are.  We will all have our own <a title="We will all of our own AWACS of things" target="_blank" href="http://en.wikipedia.org/wiki/AWACS">&#8220;Airborne Warning and Control System&#8221;</a>  following us about doing &#8216;Object Traffic Control&#8217; (&#8217;object one niner seven, please be advised that we anticipate heavy foot traffic through your sector, please take appropriate action&#8217; &#8216;this is object one niner seven, wilco on that heavy traffic&#8217;).</p>
<p>An internet of things?  That is a creaking metaphor.   I&#8217;m sorry, but I&#8217;m already almost completely flumuxed in my efforts to deal with the current Internet of Bits.  The Internet of projects and news and information and good conversation and social activism and community development and the overwhelming undertow of The Internet of CRAP!</p>
<p>Knowing where my objects are is great.  Having objects which know something about themselves is great.  They can communicate with each other, and scheme together.  If you thought managing your Stuff 1.0 objects could be maddening, wait for Stuff 2.0, where your stuff can actively conspire to drive you insane.</p>
<p>The Internet of Things: because we can make dealing with your crap even more complicated!</p>
<p>An actual conversation (transcribed from flawed memory), from ETech 2003:</p>
<p>person one &#8220;I&#8217;d like to get a roomful of Tawainese VCR and Microwave oven user interface designers in a room and tell them&#8230;&#8221;</p>
<p>Wes Felter, of <a target="_blank" title="Hack the Planet!" href="http://wmf.editthispage.com/">Hack the Planet</a> fame &#8220;Do you think there is a whole roomful of them?  I think there is just one, and the one isn&#8217;t very busy.&#8221;<br />
With apologies to <a target="_blank" title="Don't kid yourself!" href="http://www.google.com/search?q=%2B%22frank+zappa%22+%2B%27everyone+in+this+room+is+wearing+a+uniform%27&#038;btnG=Search">Frank Zappa</a>, Everyone in this room has a VCR blinking 12:00.  The &#8216;Self Improvement&#8217; industry is devoted to offering (contradictory) instructions on how to set the clocks in the various VCR&#8217;s of our life.  <a target="_blank" title="Read 43Folders, really, your VCR Clock will thank you." href="http://www.43folders.com/">Getting Things Done</a> is all about setting one clock.  The Atkins diet is another.  And in a piece of useful advice, an offer of candy, flowers, a back rub, or your relationship&#8217;s equivelent can often get the VCR Clock of your personal life running a tad smoother.<br />
Everyone has a VCR blinking 12:00.  Won&#8217;t you join me in this, say it, all together and out loud: &#8220;I have a VCR blinking 12:00.&#8221;</p>
<p>Thank you brothers, thank you sisters.</p>
<p>Being able to google your shoes will be, well, something.  But the revolution is not in your shoes.  The revolution is within.</p>
<p>As always truth comes from the bumper of a car &#8220;Lord, please help me to be the person my dog thinks I am.&#8221;  With just a little cleaning up we get &#8220;Internet, please help me to be the person who I defined myself to be in filling out my Values Clarification Matrix.&#8221;</p>
<p>The revolution is creating and using the tools to remind us of who we are when our attention is directed elsewhere.   The tools from an &#8216;internet of things&#8217; are useful, as are the buzz from &#8216;context aware computing&#8217; and &#8216;ambient computing,&#8217; but the key is to direct the technology in support of our personal values.   To drive our lives the way you drive a Prius.  To create an Internet of Values.</p>
<p>An Internet (in support) of your values.</p>
<p>obligatory mapping focused reference:  one way (right now the most obvious way to me) to implement the internet of values is to present information at the time and place where it can be acted upon.  To put your keys on top of the library book you need to return.  To provide feedback on your actions quickly enough so that you can alter your actions.
</p>
";}s:3:"wfw";a:1:{s:10:"commentrss";s:62:"http://mappinghacks.com/2006/12/07/an-internet-of-values/feed/";}s:7:"summary";s:318:"The revolution will not be televised, and the revolution will not come from the creeping crudge of &#8216;The Internet of Things.&#8217;   I&#8217;m as excited as Bruce Sterling to have technology help me to keep track of my crap.  You won&#8217;t need to look for your shoes, you&#8217;ll be able to Google Your [...]";s:12:"atom_content";s:4537:"<p>The revolution will not be televised, and the revolution will not come from the creeping crudge of &#8216;The Internet of Things.&#8217;   I&#8217;m as excited as Bruce Sterling to have technology help me to keep track of my crap.  You won&#8217;t need to look for your shoes, you&#8217;ll be able to Google Your Shoes!</p>
<p>And the truth will set us free.  The truth of knowing where we are in relation to the constellation of objects which we have allowed to assume the role of defining who we are.  We will all have our own <a title="We will all of our own AWACS of things" target="_blank" href="http://en.wikipedia.org/wiki/AWACS">&#8220;Airborne Warning and Control System&#8221;</a>  following us about doing &#8216;Object Traffic Control&#8217; (&#8217;object one niner seven, please be advised that we anticipate heavy foot traffic through your sector, please take appropriate action&#8217; &#8216;this is object one niner seven, wilco on that heavy traffic&#8217;).</p>
<p>An internet of things?  That is a creaking metaphor.   I&#8217;m sorry, but I&#8217;m already almost completely flumuxed in my efforts to deal with the current Internet of Bits.  The Internet of projects and news and information and good conversation and social activism and community development and the overwhelming undertow of The Internet of CRAP!</p>
<p>Knowing where my objects are is great.  Having objects which know something about themselves is great.  They can communicate with each other, and scheme together.  If you thought managing your Stuff 1.0 objects could be maddening, wait for Stuff 2.0, where your stuff can actively conspire to drive you insane.</p>
<p>The Internet of Things: because we can make dealing with your crap even more complicated!</p>
<p>An actual conversation (transcribed from flawed memory), from ETech 2003:</p>
<p>person one &#8220;I&#8217;d like to get a roomful of Tawainese VCR and Microwave oven user interface designers in a room and tell them&#8230;&#8221;</p>
<p>Wes Felter, of <a target="_blank" title="Hack the Planet!" href="http://wmf.editthispage.com/">Hack the Planet</a> fame &#8220;Do you think there is a whole roomful of them?  I think there is just one, and the one isn&#8217;t very busy.&#8221;<br />
With apologies to <a target="_blank" title="Don't kid yourself!" href="http://www.google.com/search?q=%2B%22frank+zappa%22+%2B%27everyone+in+this+room+is+wearing+a+uniform%27&#038;btnG=Search">Frank Zappa</a>, Everyone in this room has a VCR blinking 12:00.  The &#8216;Self Improvement&#8217; industry is devoted to offering (contradictory) instructions on how to set the clocks in the various VCR&#8217;s of our life.  <a target="_blank" title="Read 43Folders, really, your VCR Clock will thank you." href="http://www.43folders.com/">Getting Things Done</a> is all about setting one clock.  The Atkins diet is another.  And in a piece of useful advice, an offer of candy, flowers, a back rub, or your relationship&#8217;s equivelent can often get the VCR Clock of your personal life running a tad smoother.<br />
Everyone has a VCR blinking 12:00.  Won&#8217;t you join me in this, say it, all together and out loud: &#8220;I have a VCR blinking 12:00.&#8221;</p>
<p>Thank you brothers, thank you sisters.</p>
<p>Being able to google your shoes will be, well, something.  But the revolution is not in your shoes.  The revolution is within.</p>
<p>As always truth comes from the bumper of a car &#8220;Lord, please help me to be the person my dog thinks I am.&#8221;  With just a little cleaning up we get &#8220;Internet, please help me to be the person who I defined myself to be in filling out my Values Clarification Matrix.&#8221;</p>
<p>The revolution is creating and using the tools to remind us of who we are when our attention is directed elsewhere.   The tools from an &#8216;internet of things&#8217; are useful, as are the buzz from &#8216;context aware computing&#8217; and &#8216;ambient computing,&#8217; but the key is to direct the technology in support of our personal values.   To drive our lives the way you drive a Prius.  To create an Internet of Values.</p>
<p>An Internet (in support) of your values.</p>
<p>obligatory mapping focused reference:  one way (right now the most obvious way to me) to implement the internet of values is to present information at the time and place where it can be acted upon.  To put your keys on top of the library book you need to return.  To provide feedback on your actions quickly enough so that you can alter your actions.
</p>
";}i:6;a:12:{s:5:"title";s:23:"fun with schematic maps";s:4:"link";s:59:"http://mappinghacks.com/2006/12/04/fun-with-schematic-maps/";s:8:"comments";s:68:"http://mappinghacks.com/2006/12/04/fun-with-schematic-maps/#comments";s:7:"pubdate";s:31:"Mon, 04 Dec 2006 21:09:51 +0000";s:2:"dc";a:1:{s:7:"creator";s:2:"Jo";}s:8:"category";s:13:"Uncategorized";s:4:"guid";s:59:"http://mappinghacks.com/2006/12/04/fun-with-schematic-maps/";s:11:"description";s:355:"Harry Beck&#8217;s schematic map of London&#8217;s Tube network is constantly cited as a design classic and a cartographic inspiration. I am one of many people who&#8217;ve made a &#8220;spatially accurate&#8221; version of the Tube map for kicks.
ChrisDodo pointed us at an interesting spin on the idea - a schematic map of the UK motorway network. [...]";s:7:"content";a:1:{s:7:"encoded";s:1320:"<p>Harry Beck&#8217;s <a href="http://en.wikipedia.org/wiki/Tube_map">schematic map of London&#8217;s Tube network</a> is constantly cited as a design classic and a cartographic inspiration. I am one of <a href="http://www.google.co.uk/search?q=accurate+tube+map">many people who&#8217;ve made a &#8220;spatially accurate&#8221; version</a> of the Tube map for kicks.</p>
<p><a href="http://anti-mega.com/antimega/">ChrisDodo</a> pointed us at an interesting spin on the idea - a<a href="http://www.motorwaymap.co.uk/"> schematic map of the UK motorway network</a>. Being a non-driver, i have no idea whether this map is useful as well as beautiful, though.</p>
<p>The reason i mention this here is another more fun map on the motorwaymap.co.uk site - a <a href="http://www.motorwaymap.co.uk/mono.htm">spatially accurate rendering of the Monopoly board in central London</a>. I wonder what could be learned from overlaying this with census and demographic data from 1935; and whether, if Monopoly was played over London again today, the distribution and balance between rich and poor areas would have changed much over the years; I also wonder whether there&#8217;d be interesting structural similarities between spatially accurate Monopoly maps in different cities&#8230; it&#8217;s a lovely mapping hack, anyway.
</p>
";}s:3:"wfw";a:1:{s:10:"commentrss";s:64:"http://mappinghacks.com/2006/12/04/fun-with-schematic-maps/feed/";}s:7:"summary";s:355:"Harry Beck&#8217;s schematic map of London&#8217;s Tube network is constantly cited as a design classic and a cartographic inspiration. I am one of many people who&#8217;ve made a &#8220;spatially accurate&#8221; version of the Tube map for kicks.
ChrisDodo pointed us at an interesting spin on the idea - a schematic map of the UK motorway network. [...]";s:12:"atom_content";s:1320:"<p>Harry Beck&#8217;s <a href="http://en.wikipedia.org/wiki/Tube_map">schematic map of London&#8217;s Tube network</a> is constantly cited as a design classic and a cartographic inspiration. I am one of <a href="http://www.google.co.uk/search?q=accurate+tube+map">many people who&#8217;ve made a &#8220;spatially accurate&#8221; version</a> of the Tube map for kicks.</p>
<p><a href="http://anti-mega.com/antimega/">ChrisDodo</a> pointed us at an interesting spin on the idea - a<a href="http://www.motorwaymap.co.uk/"> schematic map of the UK motorway network</a>. Being a non-driver, i have no idea whether this map is useful as well as beautiful, though.</p>
<p>The reason i mention this here is another more fun map on the motorwaymap.co.uk site - a <a href="http://www.motorwaymap.co.uk/mono.htm">spatially accurate rendering of the Monopoly board in central London</a>. I wonder what could be learned from overlaying this with census and demographic data from 1935; and whether, if Monopoly was played over London again today, the distribution and balance between rich and poor areas would have changed much over the years; I also wonder whether there&#8217;d be interesting structural similarities between spatially accurate Monopoly maps in different cities&#8230; it&#8217;s a lovely mapping hack, anyway.
</p>
";}i:7;a:12:{s:5:"title";s:23:"when is the next where?";s:4:"link";s:58:"http://mappinghacks.com/2006/11/29/when-is-the-next-where/";s:8:"comments";s:67:"http://mappinghacks.com/2006/11/29/when-is-the-next-where/#comments";s:7:"pubdate";s:31:"Wed, 29 Nov 2006 23:08:26 +0000";s:2:"dc";a:1:{s:7:"creator";s:4:"Rich";}s:8:"category";s:13:"Uncategorized";s:4:"guid";s:58:"http://mappinghacks.com/2006/11/29/when-is-the-next-where/";s:11:"description";s:312:"I&#8217;ve been running around saying &#8216;when is the next where&#8217; for a bit now.      I sort of assumed it was an established meme that I was jumping on the back of, looking for uh, seconds&#8230;but a glance at Google finds zero hits for &#8220;when is the next where,&#8221; and a grep of the [...]";s:7:"content";a:1:{s:7:"encoded";s:705:"<p>I&#8217;ve been running around saying &#8216;when is the next where&#8217; for a bit now.      I sort of assumed it was an established meme that I was jumping on the back of, looking for uh, seconds&#8230;but a glance at Google finds zero hits for &#8220;when is the next where,&#8221; and a grep of the #geo log shows only one use, my own, on Aug 1 of this year, at 16:00.</p>
<p>I am doing various hopefully clever projects right now&#8230;I need to warp one so that the motto can be &#8216;foobar corp, because when is the next where&#8217;</p>
<p>Because, after all, I&#8217;m interested in communicating with that subset of a subset of  geeks who actually care about both time and space.
</p>
";}s:3:"wfw";a:1:{s:10:"commentrss";s:63:"http://mappinghacks.com/2006/11/29/when-is-the-next-where/feed/";}s:7:"summary";s:312:"I&#8217;ve been running around saying &#8216;when is the next where&#8217; for a bit now.      I sort of assumed it was an established meme that I was jumping on the back of, looking for uh, seconds&#8230;but a glance at Google finds zero hits for &#8220;when is the next where,&#8221; and a grep of the [...]";s:12:"atom_content";s:705:"<p>I&#8217;ve been running around saying &#8216;when is the next where&#8217; for a bit now.      I sort of assumed it was an established meme that I was jumping on the back of, looking for uh, seconds&#8230;but a glance at Google finds zero hits for &#8220;when is the next where,&#8221; and a grep of the #geo log shows only one use, my own, on Aug 1 of this year, at 16:00.</p>
<p>I am doing various hopefully clever projects right now&#8230;I need to warp one so that the motto can be &#8216;foobar corp, because when is the next where&#8217;</p>
<p>Because, after all, I&#8217;m interested in communicating with that subset of a subset of  geeks who actually care about both time and space.
</p>
";}i:8;a:12:{s:5:"title";s:22:"Geospatial web podcast";s:4:"link";s:58:"http://mappinghacks.com/2006/11/20/geospatial-web-podcast/";s:8:"comments";s:67:"http://mappinghacks.com/2006/11/20/geospatial-web-podcast/#comments";s:7:"pubdate";s:31:"Tue, 21 Nov 2006 07:27:19 +0000";s:2:"dc";a:1:{s:7:"creator";s:4:"Rich";}s:8:"category";s:20:"Uncategorizedpodcast";s:4:"guid";s:58:"http://mappinghacks.com/2006/11/20/geospatial-web-podcast/";s:11:"description";s:191:"Our friend Mike Liebhold is on this http://buildwebsites.net/blogs/michigan-web-design/8590/
It is an interesting podcast in which fun things are said&#8230;read the link, listen, have fun.

";s:7:"content";a:1:{s:7:"encoded";s:306:"<p>Our friend Mike Liebhold is on this <a title="geospatial web podcast" href="http://buildwebsites.net/blogs/michigan-web-design/8590/">http://buildwebsites.net/blogs/michigan-web-design/8590/</a><br />
It is an interesting podcast in which fun things are said&#8230;read the link, listen, have fun.
</p>
";}s:3:"wfw";a:1:{s:10:"commentrss";s:63:"http://mappinghacks.com/2006/11/20/geospatial-web-podcast/feed/";}s:7:"summary";s:191:"Our friend Mike Liebhold is on this http://buildwebsites.net/blogs/michigan-web-design/8590/
It is an interesting podcast in which fun things are said&#8230;read the link, listen, have fun.

";s:12:"atom_content";s:306:"<p>Our friend Mike Liebhold is on this <a title="geospatial web podcast" href="http://buildwebsites.net/blogs/michigan-web-design/8590/">http://buildwebsites.net/blogs/michigan-web-design/8590/</a><br />
It is an interesting podcast in which fun things are said&#8230;read the link, listen, have fun.
</p>
";}i:9;a:12:{s:5:"title";s:33:"Addressing the mess of addressing";s:4:"link";s:69:"http://mappinghacks.com/2006/11/18/addressing-the-mess-of-addressing/";s:8:"comments";s:78:"http://mappinghacks.com/2006/11/18/addressing-the-mess-of-addressing/#comments";s:7:"pubdate";s:31:"Sat, 18 Nov 2006 17:17:59 +0000";s:2:"dc";a:1:{s:7:"creator";s:2:"Jo";}s:8:"category";s:28:"geodataplanningannoying_gits";s:4:"guid";s:69:"http://mappinghacks.com/2006/11/18/addressing-the-mess-of-addressing/";s:11:"description";s:308:"This week, Michael Cross of the Guardian and Free Our Data has been in high dudgeon about the messed up situation for street addressing and postal code data in the UK. Licensing costs are set to double next year, for the use of the data needed to do postcode geocoding from the Royal Mail. Applications [...]";s:7:"content";a:1:{s:7:"encoded";s:4422:"<p>This week, Michael Cross of the Guardian and Free Our Data has been in high dudgeon about the messed up situation for <a href="http://technology.guardian.co.uk/weekly/story/0,,1948249,00.html">street addressing and postal code data</a> in the UK. Licensing costs are set to double next year, for the use of the data needed to do postcode geocoding from the Royal Mail. Applications for new postcodes have to be made by local government authorities, and so are tied into their planning systems, but not, say to their taxation systems.</p>
<p>My mother recently moved into a new development, and though she&#8217;s been allocated a postcode, the utility companies don&#8217;t recognise it yet, nor did the tax department of the local council when she spent some time actually attempting to pay her council tax voluntarily. All the data should be there at source; but the centralised system of submitting updates incurs delays in data propagation.</p>
<p>Well, the <a href="http://en.wikipedia.org/wiki/National_Spatial_Address_Infrastructure">National Spatial Address Infrastructure</a> was intended to change a lot of this; streamline processes and protocols for the interchange of addressing data between local government agencies. The project was quietly dropped after Ordnance Survey refused to collaborate or back down over its copyright assertions, and has gone completely into the hands of the commercial partners in the venture, &#8220;<a href="http://www.intelligent-addressing.co.uk/nlpg.htm">Intelligent Addressing</a>&#8221; as the <a href="http://www.idea-knowledge.gov.uk/idk/core/page.do?pageId=1703892">National Land and Property Gazetteer</a>. It uses a standard called <a href="http://www.govtalk.gov.uk/schemasstandards/schemalibrary_schema.asp?schemaid=65">BS 7666</a> for addressing data. But NLPG itself depends to some extent on Ordnance Survey&#8217;s AddressPoint, which in turn is redistributing amd being used to georeference the Royal Mail&#8217;s PAF data.</p>
<p>Mikel was recently wondering about the  role of <a href="http://brainoff.com/weblog/2006/11/14/1201">local authorities in syndicating updates of planning information</a>, especially for new developments. The <a href="http://www.lga.gov.uk/About.asp?lsection=456">Local Government Association</a> looks like a federation of local authorities and <a href="http://www.idea-knowledge.gov.uk/">IDeA</a>, a private company which it wholly owns and which lives in the .gov namespace, is responsible for maintaining the contract with Intelligent Addressing for the NLPG. Recall that Intelligent Addressing had a complaint against the OS upheld by the Office of Public Sector Information back in July; it judged that the OS had behaved anticompetitively, against the code of information practise that  is intended to govern it, and its licensing policy was obfuscatory, and encouraged it to try harder in future in a kind of mild, diffident admonishment. (Michael Cross points out that the NLPG only covers 320 of 366 local authorities right now (and I wonder who the missing pieces are and <em>why</em> they&#8217;re missing)).</p>
<p>In the case of the addressing mess, everyone&#8217;s data is hooked into everyone else&#8217;s, all interdependent. It can&#8217;t be unentwingled, which is why the attempt to enforce payment for use of data on proprietary terms is bound to escalate in a tit-for-tat fashion: &#8220;if we&#8217;re contributing 20% of the data, we should be extracting 20% of the future value of it from you&#8221;. Now OS is launching a <strong>competing product</strong> to the NLPG despite the OPSI&#8217;s reservations, after having walked away from the unified infrastructure discussions. Development of the NLPG is being paid for with taxpayers&#8217; money anyway, because the OS will not co-operate for proprietary data licensing reasons. Local authorities are losing money by giving data away to the OS anyway; why not share it direct with each other and with the public?</p>
<p>Meanwhile <a href="http://freethepostcode.org/">la lutte</a> <a href="http://www.npemap.org.uk">continue,</a> and at the rate the Royal Mail, OS and IDeA are going, the postcodes will be freed before the stalemate and subsequent legal fallout subsides. I wonder how interested some local authorities would be in the opportunity to georeference against and build on a free of copyright spatial/address data set at this point?
</p>
";}s:3:"wfw";a:1:{s:10:"commentrss";s:74:"http://mappinghacks.com/2006/11/18/addressing-the-mess-of-addressing/feed/";}s:7:"summary";s:308:"This week, Michael Cross of the Guardian and Free Our Data has been in high dudgeon about the messed up situation for street addressing and postal code data in the UK. Licensing costs are set to double next year, for the use of the data needed to do postcode geocoding from the Royal Mail. Applications [...]";s:12:"atom_content";s:4422:"<p>This week, Michael Cross of the Guardian and Free Our Data has been in high dudgeon about the messed up situation for <a href="http://technology.guardian.co.uk/weekly/story/0,,1948249,00.html">street addressing and postal code data</a> in the UK. Licensing costs are set to double next year, for the use of the data needed to do postcode geocoding from the Royal Mail. Applications for new postcodes have to be made by local government authorities, and so are tied into their planning systems, but not, say to their taxation systems.</p>
<p>My mother recently moved into a new development, and though she&#8217;s been allocated a postcode, the utility companies don&#8217;t recognise it yet, nor did the tax department of the local council when she spent some time actually attempting to pay her council tax voluntarily. All the data should be there at source; but the centralised system of submitting updates incurs delays in data propagation.</p>
<p>Well, the <a href="http://en.wikipedia.org/wiki/National_Spatial_Address_Infrastructure">National Spatial Address Infrastructure</a> was intended to change a lot of this; streamline processes and protocols for the interchange of addressing data between local government agencies. The project was quietly dropped after Ordnance Survey refused to collaborate or back down over its copyright assertions, and has gone completely into the hands of the commercial partners in the venture, &#8220;<a href="http://www.intelligent-addressing.co.uk/nlpg.htm">Intelligent Addressing</a>&#8221; as the <a href="http://www.idea-knowledge.gov.uk/idk/core/page.do?pageId=1703892">National Land and Property Gazetteer</a>. It uses a standard called <a href="http://www.govtalk.gov.uk/schemasstandards/schemalibrary_schema.asp?schemaid=65">BS 7666</a> for addressing data. But NLPG itself depends to some extent on Ordnance Survey&#8217;s AddressPoint, which in turn is redistributing amd being used to georeference the Royal Mail&#8217;s PAF data.</p>
<p>Mikel was recently wondering about the  role of <a href="http://brainoff.com/weblog/2006/11/14/1201">local authorities in syndicating updates of planning information</a>, especially for new developments. The <a href="http://www.lga.gov.uk/About.asp?lsection=456">Local Government Association</a> looks like a federation of local authorities and <a href="http://www.idea-knowledge.gov.uk/">IDeA</a>, a private company which it wholly owns and which lives in the .gov namespace, is responsible for maintaining the contract with Intelligent Addressing for the NLPG. Recall that Intelligent Addressing had a complaint against the OS upheld by the Office of Public Sector Information back in July; it judged that the OS had behaved anticompetitively, against the code of information practise that  is intended to govern it, and its licensing policy was obfuscatory, and encouraged it to try harder in future in a kind of mild, diffident admonishment. (Michael Cross points out that the NLPG only covers 320 of 366 local authorities right now (and I wonder who the missing pieces are and <em>why</em> they&#8217;re missing)).</p>
<p>In the case of the addressing mess, everyone&#8217;s data is hooked into everyone else&#8217;s, all interdependent. It can&#8217;t be unentwingled, which is why the attempt to enforce payment for use of data on proprietary terms is bound to escalate in a tit-for-tat fashion: &#8220;if we&#8217;re contributing 20% of the data, we should be extracting 20% of the future value of it from you&#8221;. Now OS is launching a <strong>competing product</strong> to the NLPG despite the OPSI&#8217;s reservations, after having walked away from the unified infrastructure discussions. Development of the NLPG is being paid for with taxpayers&#8217; money anyway, because the OS will not co-operate for proprietary data licensing reasons. Local authorities are losing money by giving data away to the OS anyway; why not share it direct with each other and with the public?</p>
<p>Meanwhile <a href="http://freethepostcode.org/">la lutte</a> <a href="http://www.npemap.org.uk">continue,</a> and at the rate the Royal Mail, OS and IDeA are going, the postcodes will be freed before the stalemate and subsequent legal fallout subsides. I wonder how interested some local authorities would be in the opportunity to georeference against and build on a free of copyright spatial/address data set at this point?
</p>
";}}s:7:"channel";a:7:{s:5:"title";s:13:"Mapping Hacks";s:4:"link";s:23:"http://mappinghacks.com";s:11:"description";s:42:"by Schuyler Erle, Rich Gibson and Jo Walsh";s:7:"pubdate";s:31:"Thu, 19 Apr 2007 18:07:13 +0000";s:9:"generator";s:29:"http://wordpress.org/?v=2.0.2";s:8:"language";s:2:"en";s:7:"tagline";s:42:"by Schuyler Erle, Rich Gibson and Jo Walsh";}s:9:"textinput";a:0:{}s:5:"image";a:0:{}s:9:"feed_type";s:3:"RSS";s:12:"feed_version";s:3:"2.0";s:5:"stack";a:0:{}s:9:"inchannel";b:0;s:6:"initem";b:0;s:9:"incontent";b:0;s:11:"intextinput";b:0;s:7:"inimage";b:0;s:13:"current_field";s:0:"";s:17:"current_namespace";b:0;s:5:"ERROR";s:0:"";s:19:"_CONTENT_CONSTRUCTS";a:6:{i:0;s:7:"content";i:1;s:7:"summary";i:2;s:4:"info";i:3;s:5:"title";i:4;s:7:"tagline";i:5;s:9:"copyright";}s:13:"last_modified";s:31:"Thu, 19 Apr 2007 18:07:13 GMT
";s:4:"etag";s:36:""49807e5e91407df8821482e8f9ea9e89"
";}